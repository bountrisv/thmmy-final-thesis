\chapter{Πειράματα και Αποτελέσματα}

Στο κεφάλαιο αυτό θα αναλύσουμε τα πειράματα που έγιναν για την εκπαίδευση του μοντέλου παραγωγής κώδικα και θα εξετάσουμε την ποιότητα του παραγώμενου κώδικα.
Θα εξετάσουμε ξεχωριστά κάθε σετ δεδομένων και θα συγκρίνουμε τις επιλογές και τις επιδόσεις των 2 προσεγγίσεων σε καθ' ένα απο αυτά.
Τέλος θα ελέγξουμε τις επιδόσεις του μοντέλου σε ένα υπο-προΪόν της λειτουργίας του, στην αυτόματη συμπλήρωση κώδικα.


\section{Πειράματα εκπαίδευσης}

Ένα πολύ σημαντικό κομμάτι της εκπαίδευσης ενός τέτοιου συστήματος είναι η κατάλληλη επιλογή των υπερπαραμέτρων.
Αποδεικνύεται πως η αποδοτικότερη μέθοδος για την επιλογή τους είναι η τυχαία μέθοδος \cite{Bersgstra2012}.
Η υπολογιστική πολυπλοκότητα που εισάγουν τα αναδραστικά νευρωνικά δίκτυα και οι περιορισμένοι υπολογιστικοί πόροι που έχουμε στη διάθεση μας κάνουν αυτή την επιλογή αδύνατη.
Αντ' αυτού επιλέγουμε εμπειρικά τις υπερπαραμέτρους (με δοκιμές) και με οδηγό της επιλογές στη σύγχρονη σχετική βιβλιογραφία.

\subsection{\en{Top 100 Github Javascript Projects} Πειράματα}

To σετ δεδομένων αυτό αποτελείται από τα 100 πιο δημοφιλή \en{projects} σε γλώσσα \en{javascript} στον ιστότοπο αποθετηρίων λογισμικόυ \en{github}.
Μετά τo prepocessing παίρνουμε ακολουθίες συνολικού μήκους περίπου 79 εκατομμυρίων χαρακτήρων.
Υπάρχουν 212 διαφορετικοί χαρακτήρες, συμπεριλαμβανομένων των ειδικών χαρακτήρων αρχής και τέλους αρχείων.
Χρησιμοποιούμε το 95\% των δεδομένων για την εκπαίδευση του συστήματος και το υπόλοιπο 5\% για την επικύρωση της μάθησης.
Η έλλειψη ξεχωριστού τεστ σετ μπορεί να σημαίνει οτι τα αποτελέσματα μας κάνουν overfit στα δεδομένα επικύρωσης, αλλά αυτό είναι δευτερευούσης σημασίας αφού στόχος μας είναι να παράξουμε κώδικα και δεν υπάρχει αντικειμενική μαθησιακή μετρική για τον σκοπό αυτό.

Η στρατηγική επιλογής των παραμέτρων έχει ως εξής: Για να είναι οι δύο προσεγγίσεις συγκρίσιμες κρατάμε ίδιο το μέγεθος των κρυφών επιπέδων.
Από αυτή την επιλογή εξαρτάται κυρίως ο αριθμός συνολικών παραμέτρων προς εκπαίδευση.
Για το πρώτο σετ δεδομένων αποφασίζουμε τον αριθμό αυτό σε 1024, αριθμός αρκετά μεγάλος ωστε να ειναι αντιμετωπίσιμο από το σύστημα το ογκώδες σετ δεδομένων.

Η επόμενη υπερ-παράμετρος που πρέπει να αποφασιστεί είναι το μήκος της εκπαιδευτικής ακολουθίας, η μεταβλητή $k_2$ του αλγορίθμου \en{TBPTT}.
Η υπερ-παράμετρος αυτή έχει μεγάλη σχέση τόσο με την ποιότητα του παραγώμενου κώδικα, αφού ελέγχει πόσους από τους προηγούμενους χαρακτήρες <<βλέπει>> το σύστημα, αλλά και με τον χρόνο εκτέλεσης μιας εποχής, αφού μεγαλύτερες ακολουθίες εισάγουν υπολογιστική πολυπλοκότητα.
Το μέγεθος των εκπαιδευτικων ακολυθιών αποφασίζεται στους 100 χαρακτήρες και για τα δύο μοντέλα.

Ο ρυθμός εκμάθησης είναι άμεσα συνδεδεμένος με το μέγεθος παρτίδας.
Όσο περισσότερα παραδείγματα βλέπει ταυτόχρονα το σύστημα τόσο πιο σίγουρο θα πρέπει να είναι για τα συμπεράσματα του.
Εξαγωγή δυνατών συμπερασμάτων απο λιγοστά παραδείγματα πρέπει να αποφεύγεται.
Επιπρόσθετα υπάρχει και ένας φυσικός περιορισμός στο πόσα παραδείγματα μπορούν να δείχνονται ταυτόχρονα, η μνήμη της επεξεργαστικής μας μονάδας.
Τελικώς δείχνουμε 200 ακολουθίες σε κάθε βήμα εκμάθσης και θέτουμε τον ρυθμό εκμάθησης στην τιμή 0.002, ωστέ να γεμίζουμε όσο καλύτερα γίνεται την μνήμη του υπολογιστικού συστήματος αλλά να συνεχίσουμε να μαθαίνουμε αποτελεσματικά.
Σημειώνεται πως η προτεινόμενη τιμή για τον ρυθμό εκμάθησης της \en{rmsprop} είναι το 0.001.

Τέλος, επειδή το σετ δεδομένων αυτό είναι αρκετά ογκώδες και περίπλοκο, είναι δύσκολο το μοντέλο μας να κάνει overfit. Έτσι, δε χρείαζεται η πιθανότητα dropout να είναι εξαιρετικά μεγάλη.
Επιλέγουμε την υπερπαράμετρο αυτή στο 20\%, ενώ η γενική προτεινόμενη τιμή είναι 40\% με 50\%.
Ο αριθμός των εποχών αποφασίζεται έτσι ώστε κανένα από τα 2 μοντέλα να μην βελτιώνει τις επιδόσεις του στο σετ δεδομένων επιβεβαίωσης.
Ο αριθμός αυτός προκύπτει στις 60 εποχές.
Στον πίνακα \ref{hyper1} παρουσιάζονται συνοπτικά οι παραπάνω αποφάσεις.

\begin{table}[]
\centering
\begin{tabularx}{\textwidth}{|X|X|X|}
\hline
                    & \en{char-rnn} & \en{labeled-char-rnn} \\
\hline
\en{\#} Παραμέτρων       & 23Μ             & 23Μ                     \\
\hline
\en{\#} Χαρακτήρων       & 212             & 212, 8                  \\
\hline
\en{\#} Εποχών       & 40             & 60                  \\
\hline
Μέγεθος \en{LSTM}  & 1024            & 1024                    \\
\hline
Μήκος Ακολουθίας    & 100             & 100                     \\
\hline
Ρυθμός Εκμάθησης    & 0.002           & 0.002                   \\
\hline
\% \en{Dropout}     & 20              & 20                      \\
\hline
Μέγεθος Παρτίδας    & 200             & 200                     \\
\hline
\end{tabularx}
\caption{Υπερπαράμετοι για τα \en{top 100 Github js projects}}
\label{hyper1}
\end{table}

Η εκπαίδευση έγινε σε μία κάρτα γραφικών \en{Nvidia Gtx 960} με 4 \en{gb RAM}.
Η εκπαίδευση διαρκεί 6 περίπου ημέρες για το πρώτο μοντέλο και 7 περίπου για το δεύτερο.
Όπως αναφέραμε, η παρακολούθηση των επιδόσεων και η επιλογή των σετ βαρών για την παραγωγή κώδικα γίνεται σύμφωνα με την μετρική \en{Average cross entropy per minibatch}.
Σημειώνεται πως η σύγκριση των μοντέλων στην μετρική αυτή γίνεται μόνο στο κομμάτι που αφορά την πρόβλεψη χαρακτήρων.
Στην εικόνα \ref{training1} φαίνεται η εξέλιξη της εκπαίδευσης των 2 μοντέλων στην περίοδο 40 και 60 εποχών στο σετ εκπαίδευσης και το σετ επαλήθευσης. 
%TODO Διάγραμμα training me σχόλια περι overfittinh και τετοια και επιλογής μοντέλο και ξαναγραψιμο της μετρικής που χρησιμοποιείται 1 + 0.2. Σχολιασμός των accuracy
Ως μοντέλα παραγωγής, επιλέγουμε αυτά με τα βάρη τις 38ης εποχής για το μοντέλο \en{char-rnn} και της 53 εποχής για το μοντέλο \en{labeled-char-rnn}, αφού παρουσιάζουν την ελάχιστη τιμή της μετρικής μας.
Οι επιδόσεις των μοντέλων αυτών αντιστοιχόυν σε 85.6\% και 87.2\% ποσοστιαία επιτυχία στην πρόβλεψη του επόμενου χαρακτήρα.
Η επιτυχία πρόβλεψης του είδους του χαρακτήρα στο σετ επαλήθευσης βρίσκεται πάνω από το 97\%.   

\begin{figure}[h]
	\includegraphics[trim = 2 2 2 2, clip, keepaspectratio]{images/training1.png}
	\centering
	\caption{Καμπύλες εκμάθησης για τα \en{top 100 github js projects}}
	\label{training1}
\end{figure}

\subsection{\en{Top 200 node.js Projects} Πειράματα}